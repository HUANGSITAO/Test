## 2016.8.24 ##
**登录验证完成**</br>
完成C#请求HTTP，返回一个json格式字符串</br>
将字符串解析为C#对象格式@[{..}]</br>
由于返回的字符串格式为{}，所以需要加上@[]</br>
**异步函数中不能只用函数外的变量和控件变量**</br>
aynas修饰的函数为异步函数，返回值只能是void、Task和Task<T></br>
其中不能使用函数外的变量和控件变量</br>
解决：</br>
将需要返回的变量设置为static，在函数中即可使用</br>
可以通过参数传递方式使用函数外的变量
## 2016.8.25 ##
搞了大半天opencv显示摄像头图像的问题</br>
opencv库只能在C++下使用，在C#中使用opencvSharp（也有其他的）</br>
出现问题：只能在opencv窗口弹出的情况下才能在WPF窗口显示摄像头的图像。</br>
未解决。(现已解决)

下午解决了两个遗留问题：</br>
1.获取的视频流播放一段时间后卡住不动。</br>
原因：每次获取图片都占用了一块内存，并未释放</br>
解决办法：GC.*** 强制清除内存</br>
2.点击关闭后程序并未退出，只能强制关闭</br>
原因：获取摄像头视频流的过程相当于一个线程</br>
解决办法：在关闭的函数中调用close函数，cam.close()
## 2016.9.11 ##
使用C++完成获取摄像头视频+矫正+编码</br>
问题：
编码出来的H264文件不能连续推流</br>
解决：
程序显式调用动态链接库，将
<pre><code>HINSTANCE encodeLib;
ENCODE  encode_Add;
WRITEBMPTOARR WriteBmpToArr_Add;</code></pre>
都放在全局，并且在主线程中进行获取函数地址等初始化之后，生成的h264文件可以成功连续推流。</br>
又出现问题：
只有在编码只编出一个H264文件的时候，这个1.h264可以正常连续推流，如果再生成第二个2.h264文件，这两个文件在连续推流的
时候都会在推第二个文件的时候崩溃。</br>
怀疑原因：
编码的库只加载了一次。</br>
解决：
在每次编码的时候都重新加载编码DLL，使用ffplay播放成功，使用网页播放失败</br>
程序目录：E:\simplest\_librtmp\_example-master 2\simplest\_librtmp\_send264
## 2016.9.13 ##
[http://www.360doc.com/content/14/0514/10/13084517_377465379.shtml](http://www.360doc.com/content/14/0514/10/13084517_377465379.shtml "x264编码范例")
### 上午 ###
使用ffmpeg进行编码，每n帧编码一次，然后进行推流，编码中有可能失败，只要有一个失败就不能进行推流，而且推流的速度很慢，NALU大小大的超过10w</br>
本来C++编写的获取摄像头+美颜+编码+推流的程序在获取摄像头视频的时候会崩溃，因为该程序与矫正程序从摄像头获取的都是Mat类型，所以将编码和推流程序移植到矫正显示的代码上，能够成功运行。但是并不能播放推流视频。</br>
该程序每次获取一帧图像并进行编码，然后推流；每次推流一帧大小，每次都是先连接，然后发送再关闭连接。</br>
更改视频分辨率会对程序有影响
### 下午 ###
发现程序运行一段时间之后会中断，注释掉推流的代码部分后，程序每执行一次，内存增长200-300k大小，有内存泄漏问题。</br>
通过对不同代码的注释，查找是哪里的内存未释放掉，最后发现当有这一句的时候，内存不断增长。
<pre><code>x264_picture_alloc(pic_in, X264_CSP_I420, width, height);
</code></pre>
百度搜索到x264\_picture\_alloc函数的代码
<pre><code>
 int x264_picture_alloc( x264_picture_t *pic, int i_csp, int i_width, int i_height )  
{
    //指明被编码图像的类型，有X264_TYPE_AUTO、X264_TYPE_IDR、X264_TYPE_I、X264_TYPE_P、X264_TYPE_BREF、X264_TYPE_B
    //可供选择，初始化为AUTO，说明由x264在编码过程中自行控制。 
    pic->i_type = X264_TYPE_AUTO; 
   
    pic->i_qpplus1 = 0; //强制量化器，此参数减1代表当前画面的量化参数值。  
    pic->img.i_csp = i_csp; //图像颜色空间参数，目前只支持I420/YUV420.  
    pic->img.i_plane = 3; //颜色空间数目，如I420是3  
    pic->img.plane[0] = x264_malloc( 3 * i_width * i_height / 2 );//这一句动态分配了空间，需要释放  
    if( !pic->img.plane[0] )  
        return -1;  
    pic->img.plane[1] = pic->img.plane[0] + i_width * i_height;  
    pic->img.plane[2] = pic->img.plane[1] + i_width * i_height / 4;  
    pic->img.i_stride[0] = i_width;  
    pic->img.i_stride[1] = i_width / 2;  
    pic->img.i_stride[2] = i_width / 2;  
    pic->param = NULL;  
    return 0;  
}
</code></pre>
<pre><code>void *x264_malloc( int i_size )  
{  
    uint8_t *align_buf = NULL;  
#ifdef SYS_MACOSX  
    /* Mac OS X always returns 16 bytes aligned memory */  
    align_buf = malloc( i_size );  
#elif defined( HAVE_MALLOC_H )  
    align_buf = memalign( 16, i_size );  
#else  
    uint8_t *buf = malloc( i_size + 15 + sizeof(void **) + sizeof(int) );返回指向分配域起始地址的指针，buf值为0x00b9dca0  
    if( buf )  
    {  
        align_buf = buf + 15 + sizeof(void **) + sizeof(int);//此处执行完后align_buf后的值为0x00b9dcb7.  
        align_buf -= (intptr_t) align_buf & 15; //typedef  _W64 int    intptr_t;，_W64就是__w64，是为了解决32位与64位编译器的兼容性而设置的关键字   用于指针运算  。此处执行完后align_buf后的值为0x00b9dcb0.  
   
        *( (void **) ( align_buf - sizeof(void **) ) ) = buf;  
        *( (int *) ( align_buf - sizeof(void **) - sizeof(int) ) ) = i_size;  
    }  
#endif  
    if( !align_buf )  
        x264_log( NULL, X264_LOG_ERROR, "malloc of size %d failed/n", i_size );  
    return align_buf;  
} 
</code></pre>
在pic->img.plane[0] = x264\_malloc( 3 * i_width * i\_height / 2 );中申请了内存，但是程序并没有释放掉，所以导致了内存泄漏。</br>
与x264\_picture\_alloc对应的释放函数是x264\_picture\_clean(x264\_picture\_t *pic),用来释放pic中申请的内存</br>
**出现问题**
当使用x264\_picture\_t函数释放内存时，总是在这里中断。</br>
**解决**</br>
原来用法
<pre><code>pic_in->img.plane[0] = yuv_buffer;
pic_in->img.plane[1] = pic_in->img.plane[0] + width * height;
pic_in->img.plane[2] = pic_in->img.plane[1] + width * height
</code></pre>
改成
<pre><code>memcpy(pic_in->img.plane[0], yuvbuffer, width * height);
memcpy(pic_in->img.plane[1], yuvbuffer + width * height, width * height / 4);
memcpy(pic_in->img.plane[2], yuvbuffer + width * height * 5 / 4, width * height / 4);
</code></pre>
成功运行</br>
**可能原因**
原来的做法只是为pic_in指针进行了赋值，自己本身并没有内存。而x264\_picture\_clean(x264\_picture\_t *pic)函数功能为清空 pic指针申请的内存，pic中不仅有img.plane而且有其他变量申请内存，在该函数中需要释放。由于pic\_in指针不为空，并且pic\_in中的plane每一个值都指向yuv\_buffer中的一块连续内存，所以无法释放pic\_in中plane的内存，程序崩溃。
### 晚上 ###
整理文件夹(今天移动硬盘和球杆到了)
## 2016.9.14 ##
找到了张晖使用ffmpeg编写的编码+推流的程序和另一个编码+推流的程序，可以从摄像头获取视频流进行编码并使用rtmp推流，可以看。</br>
需要自己增加矫正部分代码。</br>
难点：需要将AVFrame 转 Mat类型，再将 得到的Mat类型作为参数进行矫正并返回一个新的Mat类型图像，再将这个Mat类型图像转化为AVFrame类型。
## 2016.9.15 - 2016.9.17 ##
中秋3天假
## 2016.9.17 ##
公司呆了一天。。。。随便看了一下
## 2016.9.18 ##
解决了几个比较大的问题。
AVFrame类型转Mat类型
<pre><code>AVFrame *pFrameBGR;
struct SwsContext *img_convert_ctx_bgr, *img_convert_correct;
img_convert_ctx_bgr = sws_getContext(ifmt_ctx->streams[videoindex]->codec->width, ifmt_ctx->streams[videoindex]->codec->height,ifmt_ctx->streams[videoindex]->codec->pix_fmt, pCodecCtx->width, pCodecCtx->height, PIX_FMT_BGR24, SWS_BICUBIC, NULL, NULL, NULL);
pFrameBGR = av_frame_alloc();//初始化一帧图像
uint8_t *out_buffer_bgr = (uint8_t *)av_malloc(avpicture_get_size(PIX_FMT_BGR24, pCodecCtx->width, pCodecCtx->height));//自己申请像素空间
//矫正后的AVFrame类型图片转化为源程序中的AVFrame，RGB24类型转换为YUV420P，大小从1600\*1600到指定大小。
img_convert_correct = sws_getContext(1600, 1600,
		PIX_FMT_BGR24, pCodecCtx->width/2, pCodecCtx->height/2, PIX_FMT_YUV420P, SWS_BICUBIC, NULL, NULL, NULL);

avpicture_fill((AVPicture *)pFrameBGR, out_buffer_bgr, PIX_FMT_BGR24, pCodecCtx->width, pCodecCtx->height);//填充
//avcodec_decode_video2后面的if语句中添加以下代码
if (dec_got_frame){
	sws_scale(img_convert_ctx_bgr, (const uint8_t* const*)pframe->data, pframe->linesize, 0, pCodecCtx->height, pFrameBGR->data, pFrameBGR->linesize);
	//mat为AVFrame转换过来的Mat类型变量
	Mat mat(pframe->height, pframe->width, CV_8UC3, pFrameBGR->data[0], pFrameBGR->linesize[0]);
	//矫正后的Mat类型图片
	Mat out = GetCorrectionFrame(mat);
	//Mat转AVFrame类型变量
	AVFrame outFrame = cvmat_to_avframe(&out);
	sws_scale(img_convert_correct, (const uint8_t* const*)outFrame.data, outFrame.linesize, 0, pCodecCtx->height, pFrameYUV->data, pFrameYUV->linesize);
}
</code></pre>
### cvmat\_to\_avframe() ###
<pre><code>AVFrame cvmat_to_avframe(cv::Mat* frame)
{
	AVFrame dst;
	cv::Size frameSize = frame->size();
	AVCodec *encoder = avcodec_find_encoder(AV_CODEC_ID_H264);
	AVFormatContext* outContainer = avformat_alloc_context();
	AVStream *outStream = avformat_new_stream(outContainer, encoder);
	avcodec_get_context_defaults3(outStream->codec, encoder);

	outStream->codec->pix_fmt = AV_PIX_FMT_YUV420P;
	outStream->codec->width = frame->cols;
	outStream->codec->height = frame->rows;
	//这里必须填充为BGR24类型的
	avpicture_fill((AVPicture*)&dst, frame->data, PIX_FMT_BGR24, outStream->codec->width, outStream->codec->height);
	//avpicture_fill((AVPicture*)&dst, frame->data, PIX_FMT_YUV420P, outStream->codec->width, outStream->codec->height);
	dst.width = frameSize.width;
	dst.height = frameSize.height;
	//SaveFrame(&dst,dst.width,dst.height,0);
	SaveAsBMP(&dst, dst.width, dst.height, 1, 24);
	return dst;
}
</code></pre>
推流成功，存在问题：推过去的图像是倒转的。
## 2016.9.19 ##
解决图像翻转问题，然而并没有什么用。
<pre><code>//图像翻转
pFrameYUV->data[0] += pFrameYUV->linesize[0] * (pCodecCtx->height - 1);
pFrameYUV->linesize[0] *= -1;
pFrameYUV->data[1] += pFrameYUV->linesize[1] * (pCodecCtx->height / 2 - 1);
pFrameYUV->linesize[1] *= -1;
pFrameYUV->data[2] += pFrameYUV->linesize[2] * (pCodecCtx->height / 2 - 1);
pFrameYUV->linesize[2] *= -1;
</code></pre>
### 晚上 ###
将代码整合在了一起，并使用ffmpeg获取2个视频输入设备，将两个设备获得的图像传入矫正+拼接的函数，返回一个Mat类型的指针，再将这个Mat类型转化为AVFrame类型。由于不知道返回的图像大小，所以剩下更改参数的问题留给明天。
## 2016.9.21 ##
将摄像头的输入变成了opencv获取。</br>
将视频获取以及推流写在了类中</br>
将新的代码整合在一起，程序在拼接循环中中断。
## 2016.9.22 ##
解决了拼接循环中中断的问题，原因是配置文件加载的不对。</br>
尝试将矫正拼接与编码推流分别写在线程中</br>
## 2016.9.23 ##
问题：在如果将矫正拼接的代码写在线程中，其中#pragma omp parallel for会变得无法使用，加上之后就会崩溃。</br>
只将编码推流的代码写在线程中，矫正拼接写在主线程run中。</br>
程序正常运行，在几分钟之后可能崩溃。
## 2016.9.29 ##
解决了推流音频代码跑不通的bug</br>
使用源程序提供的rtmp地址：rtmp://192.168.65.129:1935/myapp/test</br>
运行后走到avio_open(输出设备)这句时，按F11就会出现real-time buffer..too full的错误，后面的代码根本不走了</br>
使用之前的rtmp地址：rtmp://3852.liveplay.myqcloud.com/live/3852\_ef0611ce6a0211e6a2cba4dcbef5e35a</br>
会出现WriteN, RTMP send error 10053 <136 bytes>等3个错误</br>
将地址改为新供应商提供的rtmp地址：rtmp://push.258star.com/live258/83033605</br>
程序成功执行。但是在声音上不知道是否推流过去。